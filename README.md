### ukrainian_readability project

## ğŸ’¡ Description of the Problem

Although readability formulas such as *Flesch Reading Ease* and *Flesch-Kincaid Grade Level* exist for English and some other languages, Ukrainian currently lacks any established computational model to automatically assess text difficulty.
This creates challenges for Ukrainian language learners, teachers, and educational material developers, who have no objective way to evaluate whether a text is appropriate for a given proficiency level.

To address this gap, I used the Ukrainian Textbook Readability Dataset created by Sergii Prykhodchenko et al., which contains linguistic statistics extracted from Ukrainian school textbooks (Grades 1â€“9).
The original researchers focused on comparing various readability formulas, but their raw dataset also provides detailed structural features (word counts, sentence lengths, syllable counts, etc.).

In this project, I:

* Focused only on the raw linguistic features rather than the Flesch-style readability indices.
* Reorganized the data into five aggregated difficulty levels (Beginner â†’ Academic).
* Performed feature analysis and model training using Random Forest and XGBoost classifiers.
* Achieved 95% accuracy in predicting the difficulty level of a given text passage.

This model can later be used to estimate the difficulty of Ukrainian texts for language learners, helping educators and developers automatically classify materials by reading level.


## ğŸ“š Data Source

The dataset used in this project is based on the Ukrainian Textbook Readability Dataset by
[Sergii Prykhodchenko](https://github.com/prykhodchenkosd/ukrtb).  
The original dataset includes linguistic statistics extracted from Ukrainian school textbooks
(Grades 1â€“9). It was used here under an open-source academic license for educational purposes.

All preprocessing, labeling, and level assignments (elementary â†’ academic) were performed by me.


## ğŸ§¹ Data Preparation and Cleaning

Briefly:

* Combined and cleaned datasets from Grades 1â€“9
* Added difficulty level labels: Beginner â†’ Academic
* Handled missing values in AvgWord in Syl using mean imputation
* Saved cleaned dataset as combined_clean.csv


## ğŸ“ˆ Exploratory Data Analysis (EDA)


Include combined image:

![Feature Distributions](images/feature_distributions.png)

### Pairplot Analysis


![Pairplot](images/pairplot.png)


## ğŸŒ¡ï¸ Correlation Heatmap Description

To identify relationships between features, I plotted a correlation heatmap of all numeric variables.
The analysis revealed strong positive correlations between features such as Words, Letters, and Sentences, which all reflect text length.
At the same time, AvgWord in Syl and AvgWord in Letters showed weaker correlations with other variables, indicating they capture distinct linguistic properties.

This confirmed that word-level features contribute unique information about text complexity, justifying their inclusion in the final model.

![Correlation Heatmap](images/correlation_heatmap.png)


## ğŸ¤– Model Training and Results



## ğŸ§© Feature Importance Analysis



![Feature Importance](images/feature_importance.png)



## ğŸ§® Confusion Matrix and Evaluation



![Confusion Matrix](images/confusion_matrix.png)


## ğŸ§° Project Structure



```

midterm_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ res1-5.xlsx
â”‚   â”œâ”€â”€ res2_1-5.xlsx
â”‚   â”œâ”€â”€ combined_clean.csv
â”‚   â””â”€â”€ README_data.md
â”‚
â”œâ”€â”€ EDA/
â”‚   â””â”€â”€ readability_EDA.ipynb
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ ukrainian_readability_model.pkl
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ feature_distributions.png
â”‚   â”œâ”€â”€ pairplot.png
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚
â””â”€â”€ README.md

```



## ğŸ³ Docker Usage



## ğŸš€ Deployment

* Optional: URL or note that the service runs locally via Docker (127.0.0.1:8000)
* Add short explanation how to run it with docker run or uvicorn.


## ğŸ™ Acknowledgments

Dataset by [Sergii Prykhodchenko](https://github.com/prykhodchenkosd/ukrtb)
ML Zoomcamp by Alexey Grigorev
Special thanks for open educational resources and Ukrainian NLP community inspiration.


